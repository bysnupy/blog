# Title: Understanding "PLEG is not healthy"

In this article, I'd like to talk about "PLEG is not healthy" issue, sometimes which is leading "NodeNotReady" status. 
As understanding how the PLEG works, it will be much helpful for the troubleshooting.

## What is the PLEG ?

PLEG is stand for Pod Lifecycle Event Generator, 
this module in kubelet(Kubernetes) convert accordingly the container runtime states with each matched pod-level event,
and maintain the pod cache up-to-date by applying changes.

We will take a look around the red dot line part from below process image.
![original_pleg_flow_image](https://github.com/bysnupy/blog/blob/master/kubernetes/orig-pleg.png)

This image is from [Kubelet: Pod Lifecycle Event Generator (PLEG)](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md).

## How does "PLEG is not healthy" happen ?
Kubelet keeps checking PLEG health by calling `Healthy()` periodically in `SyncLoop()` as follows. 

`Healthy()` checks whether "relist" process(the PLEG key task) completes within 3 minutes.
This function is added to `runtimeState` as "PLEG", and it's calling periodically from `SyncLoop`(calling every 10s). 
If the "relist" process take times more than 3 minutes, "PLEG is not healthy" issue happens through this stack processes.
We got to know the "relist" is key task for this issue at now.

```go
// pkg/kubelet/pleg/generic.go - Healthy()
// the source codes in this article has been modified simply for readability.
relistThreshold = 3 * time.Minute

func (g *GenericPLEG) Healthy() (bool, error) {
	if elapsed > relistThreshold {
		return false, fmt.Errorf("pleg was last seen active %v ago; threshold is %v", elapsed, relistThreshold)
	}
}

// pkg/kubelet/kubelet.go - NewMainKubelet()
func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ... {
	klet.runtimeState.addHealthCheck("PLEG", klet.pleg.Healthy)
}

// pkg/kubelet/kubelet.go - syncLoop()
func (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {
	for {
		if rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 {
			time.Sleep(duration)
			duration = time.Duration(math.Min(float64(max), factor*float64(duration)))
			continue
		}
	}
}

// pkg/kubelet/runtime.go - runtimeErrors()
func (s *runtimeState) runtimeErrors() []string {
	for _, hc := range s.healthChecks {
		if ok, err := hc.fn(); !ok {
			ret = append(ret, fmt.Sprintf("%s is not healthy: %v", hc.name, err))
		}
	}
}
```

## Review "relist"

Take a look more details about "relist" function as follows. 
Specifically look at the remote process calls with other parts and check how to process the getting data,
because those parts are easy to bottleneck usually.

![PLEG_process_flow](https://github.com/bysnupy/blog/blob/master/kubernetes/PLEG.png)

In the same order above flow chart, check the process and implementations in the "relist". Refer [here](https://github.com/openshift/origin/blob/release-3.11/vendor/k8s.io/kubernetes/pkg/kubelet/pleg/generic.go#L180-L284) for full source codes.

Even though "relist" is setting as calling every 1s, however itself can take more than 1s to finish, 
if the container runtime responds slowly and/or when there are many container changes in one cycle.
So next "relist" can call after previous one is complete. 
For example, if "relist" takes time 5s to complete, then next relist time is after 6s(1s + 5s).

```go
// pkg/kubelet/kubelet.go - NewMainKubelet()
plegRelistPeriod = time.Second * 1

func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ... {
	klet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{})
}
// pkg/kubelet/pleg/generic.go - Start()

// Start spawns a goroutine to relist periodically.
func (g *GenericPLEG) Start() {
	go wait.Until(g.relist, g.relistPeriod, wait.NeverStop)
}
func (g *GenericPLEG) relist() {
...snip...
}
```

The function process starts as recording some metrics for Prometheus, such like `kubelet_pleg_relist_latency_microseconds`.
And then take all pods(included stopped pods) list from container runtime using CRI interface for getting current pods status.
This pods list is using for comparison with previous pods list to check changes and the matched pod-level events are generated along the changed states.

```go
// pkg/kubelet/pleg/generic.go - relist()

  timestamp := g.clock.Now()
  defer func() {
    metrics.PLEGRelistLatency.Observe(metrics.SinceInMicroseconds(timestamp))
  }()
  
  // Get all the pods.
	podList, err := g.runtime.GetPods(true)  
```

After getting all pods, last "relist" time is updated as current timestamp. In other words, `Healthy()` can be evaluated by this updated timestamp.

```go
  g.updateRelistTime(timestamp)
```

As mentioned previously, after comparing between current and previous pods list, 
every matched pod-level event is generated by the differences/changes between both lists here.
```go
// Compare the old and the current pods, and generate events.
  eventsByPodID := map[types.UID][]*PodLifecycleEvent{}
  for pid := range g.podRecords {
    oldPod := g.podRecords.getOld(pid)
    pod := g.podRecords.getCurrent(pid)
    // Get all containers in the old and the new pod.
    allContainers := getContainersFromPods(oldPod, pod)
    for _, container := range allContainers {
      events := computeEvents(oldPod, pod, &container.ID)
      for _, e := range events {
        updateEvents(eventsByPodID, e)
      }
    }
  }
```

The last process is If there are events associated with a pod, we should update the podCache as follows.
`updateCache()` will inspect each pod and update it one by one in single loop, 
so if many pods changed during the same "relist" period this process can be bottleneck.

```go
  for pid, events := range eventsByPodID {
    pod := g.podRecords.getCurrent(pid)
    if g.cacheEnabled() {
      if err := g.updateCache(pod, pid); err != nil {
        glog.Errorf("PLEG: Ignoring events for pod %s/%s: %v", pod.Name, pod.Namespace, err)
    }
    // Update the internal storage and send out the events.
    g.podRecords.update(pid)
    for i := range events {
      g.eventChannel <- events[i]
    }
  }
```

We has reviewed the "relist" process based on source code which has been modified simply for readability.
I hope you can learn more details about PLEG and how to take/update the required data in the process.

## Conclusions
In my experience and searching, "PLEG is not healthy" can happen various causes as follows.

- Container runtime latency or timeout (performance degradation, deadlock, bugs ...) during remote requests
- Too many running pods (events and latency is increasing proportionl to the pod numbers.)
- [Deadlock in PLEG relist](https://github.com/kubergitetes/kubernetes/issues/72482), it fixed at Kubernetes 1.14.
- CNI bugs when getting a pod network status.

### References
- [Kubelet: Pod Lifecycle Event Generator (PLEG)](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md)
- [Kubelet: Runtime Pod Cache](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/runtime-pod-cache.md)
- [relist() in kubernetes/pkg/kubelet/pleg/generic.go](https://github.com/openshift/origin/blob/release-3.11/vendor/k8s.io/kubernetes/pkg/kubelet/pleg/generic.go#L180-L284)
